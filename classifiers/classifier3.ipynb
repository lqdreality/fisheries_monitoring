{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras import __version__ as keras_version\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in each class of the original data:\n",
      "SHARK \t176\n",
      "DOL \t117\n",
      "NoF \t465\n",
      "LAG \t67\n",
      "ALB \t1719\n",
      "YFT \t734\n",
      "OTHER \t299\n",
      "BET \t200\n",
      "Total number of examples in original data: 3777\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 8574\n",
    "INPUT_WIDTH = 224\n",
    "INPUT_HEIGHT = 224\n",
    "DATA_PATH = '/a/data/fisheries_monitoring/data/classifiers/superbox/'\n",
    "ORIG_PATH = DATA_PATH + 'original'\n",
    "ORIG_DIST = {}\n",
    "CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "for cls in  CLASSES:\n",
    "    files = glob.glob(ORIG_PATH + '/' + cls + '/*.jpg')\n",
    "    ORIG_DIST[cls] = len(files)\n",
    "print \"Number of examples in each class of the original data:\"\n",
    "for key, val in ORIG_DIST.iteritems():\n",
    "    print key, '\\t', val\n",
    "ORIG_SIZE = sum(ORIG_DIST.values())\n",
    "print \"Total number of examples in original data:\", ORIG_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_all_labels(folders):\n",
    "    all_img = []\n",
    "    all_file_class = []\n",
    "    for folder in folders:\n",
    "        img = []\n",
    "        file_class = []\n",
    "        folder_name = os.path.basename(folder)\n",
    "        print('Loading augmentation: {}'.format(folder_name))\n",
    "        classes = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "        for idx, cls in enumerate(classes):\n",
    "            path = os.path.join(DATA_PATH, folder, cls, '*.jpg')\n",
    "            files = sorted(glob.glob(path))\n",
    "            for fl in files:\n",
    "                flbase = os.path.basename(fl)\n",
    "                img.append(folder_name + '/' + cls + '/' + flbase)\n",
    "                file_class.append(idx) \n",
    "        print \"Number of examples:\", len(file_class)\n",
    "        print \"Times of original:\", len(file_class)/ORIG_SIZE\n",
    "        print\n",
    "        all_img += img\n",
    "        all_file_class += file_class\n",
    "    all_labels = pd.DataFrame({\"img\":all_img, \"classes\":all_file_class})\n",
    "    all_labels = all_labels[[\"img\", \"classes\"]]\n",
    "    return all_labels\n",
    "\n",
    "\n",
    "\n",
    "def train_val_labels_split(labels, train_size = 0.8):\n",
    "    org_labels = labels[labels[\"img\"].str.startswith(\"original\")]\n",
    "    print \"original data size:\", len(org_labels)\n",
    "    train = []\n",
    "    test = []\n",
    "    for i in xrange(8):\n",
    "        train_tmp, test_tmp = train_test_split(org_labels[org_labels[\"classes\"] == i], train_size = train_size, random_state = RANDOM_STATE)\n",
    "        train.append(train_tmp)\n",
    "        test.append(test_tmp)\n",
    "    return pd.concat(train), pd.concat(test)\n",
    "\n",
    "def aug_train_labels(labels):\n",
    "    aug = []\n",
    "    i = 0\n",
    "    for label in labels[\"img\"]:\n",
    "        label = label[9:-4]\n",
    "        aug.append(all_labels[all_labels[\"img\"].str.contains(label)])\n",
    "        if (i+1) in [k*len(labels)/5 for k in xrange(1,6)]:\n",
    "            print \"Loading augmentated training data...{}% done!\".format((i+2)*100/len(labels))\n",
    "        i += 1\n",
    "    return pd.concat(aug)\n",
    "\n",
    "def data_generator(batch_size, labels, INPUT_WIDTH, INPUT_HEIGHT):\n",
    "    while True:\n",
    "        img_batch = np.zeros((batch_size, INPUT_WIDTH, INPUT_HEIGHT, 3))\n",
    "        class_batch = np.zeros((batch_size, 8))\n",
    "        for i in xrange(batch_size):\n",
    "            n = np.random.choice(len(labels))\n",
    "            file_name = labels.iloc[n][\"img\"]\n",
    "            path = DATA_PATH + file_name\n",
    "            img = image.load_img(path)\n",
    "            img = img.resize((INPUT_WIDTH, INPUT_HEIGHT))\n",
    "            img = image.img_to_array(img)\n",
    "            img /= 255\n",
    "            img_batch[i] = img\n",
    "            \n",
    "            class_batch[i] = np_utils.to_categorical(labels.iloc[n][\"classes\"], 8)\n",
    "        \n",
    "        yield (img_batch, class_batch)\n",
    "\n",
    "\n",
    "def load_data(labels, INPUT_WIDTH, INPUT_HEIGHT):\n",
    "    X = []\n",
    "    y = []\n",
    "    idx = []\n",
    "    X_raw = []\n",
    "    y_raw = [] \n",
    "    shape_raw = []\n",
    "    for i in xrange(len(labels)):\n",
    "        file_name = labels.iloc[i][\"img\"]\n",
    "        path = DATA_PATH + file_name\n",
    "        img_raw = image.load_img(path)\n",
    "        img = img_raw.resize((INPUT_WIDTH,INPUT_HEIGHT))\n",
    "        \n",
    "        img_raw = image.img_to_array(img_raw)\n",
    "        img_raw /= 255\n",
    "        img = image.img_to_array(img)\n",
    "        img /= 255\n",
    "        \n",
    "        file_class = labels.iloc[i][\"classes\"]\n",
    "\n",
    "        X.append(img)\n",
    "        y.append(file_class)\n",
    "        idx.append(file_name)\n",
    "        X_raw.append(img_raw)\n",
    "        \n",
    "        if (i+1) in [k*len(labels)/5 for k in xrange(1,6)]:\n",
    "                print \"Loading...{}% done!\".format((i+2)*100/len(labels))\n",
    "        \n",
    "    return np.array(X), np.array(y), np.array(idx), np.array(X_raw)\n",
    "\n",
    "\n",
    "def visualize_prediction(img, index = None, true_box = None, pred_box = None, ax = None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, 1, figsize=(12,8))\n",
    "    ax.imshow(img)\n",
    "    if index is not None:\n",
    "        ax.set_title(index)\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    \n",
    "    if true_box is not None:\n",
    "        x, y, w, h = true_box\n",
    "        x = x * width\n",
    "        y = y * height\n",
    "        w = w * width\n",
    "        h = h * height\n",
    "        ax.add_patch(\n",
    "        patches.Rectangle(\n",
    "            (x, y), # x,y\n",
    "            w, # width\n",
    "            h, # height\n",
    "            hatch='\\\\',\n",
    "            fill=False,      # remove background\n",
    "            color = 'r',\n",
    "            linewidth = 2.5\n",
    "                )\n",
    "            )\n",
    "    if pred_box is not None:\n",
    "        x, y, w, h = pred_box\n",
    "        x = x * width\n",
    "        y = y * height\n",
    "        w = w * width\n",
    "        h = h * height\n",
    "        ax.add_patch(\n",
    "        patches.Rectangle(\n",
    "            (x, y), # x,y\n",
    "            w, # width\n",
    "            h, # height\n",
    "            hatch='-',\n",
    "            fill=False,      # remove background\n",
    "            color = 'k',\n",
    "            linewidth = 2.5\n",
    "                )\n",
    "            )\n",
    "\n",
    "def make_plot(data, nrow = 2, ncol = 2, index = None, true_box = None, pred_box = None, figsize = (15,8)):\n",
    "    # Create grid\n",
    "    _, ax = plt.subplots(nrow, ncol, figsize=figsize)\n",
    "    \n",
    "    idx = None\n",
    "    tbox = None\n",
    "    pbox = None\n",
    "    # Generate indices of images to show\n",
    "    for axi in np.ravel(ax):\n",
    "        n = np.random.choice(len(data))\n",
    "        img = data[n]\n",
    "        if index is not None:\n",
    "            idx = index[n]\n",
    "        if true_box is not None:\n",
    "            tbox = true_box[n]\n",
    "        if pred_box is not None:\n",
    "            pbox = pred_box[n]\n",
    "        \n",
    "        # Visualize it along with the box\n",
    "        visualize_prediction(img, index = idx, true_box = tbox, pred_box = pbox, ax = axi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading augmentation: invert\n",
      "Number of examples: 22662\n",
      "Times of original: 6\n",
      "\n",
      "Loading augmentation: vflip\n",
      "Number of examples: 15108\n",
      "Times of original: 4\n",
      "\n",
      "Loading augmentation: add\n",
      "Number of examples: 22662\n",
      "Times of original: 6\n",
      "\n",
      "Loading augmentation: emboss\n",
      "Number of examples: 11331\n",
      "Times of original: 3\n",
      "\n",
      "Loading augmentation: gaussianNoise\n",
      "Number of examples: 33993\n",
      "Times of original: 9\n",
      "\n",
      "Loading augmentation: blur\n",
      "Number of examples: 22662\n",
      "Times of original: 6\n",
      "\n",
      "Loading augmentation: original\n",
      "Number of examples: 3777\n",
      "Times of original: 1\n",
      "\n",
      "Loading augmentation: dropout\n",
      "Number of examples: 7554\n",
      "Times of original: 2\n",
      "\n",
      "Loading augmentation: rotate\n",
      "Number of examples: 11331\n",
      "Times of original: 3\n",
      "\n",
      "Total number of examples: 151080\n",
      "Total number of times of original: 40\n"
     ]
    }
   ],
   "source": [
    "all_folders = glob.glob(DATA_PATH + '*')\n",
    "all_labels = load_all_labels(all_folders)\n",
    "print \"Total number of examples:\", len(all_labels)\n",
    "print \"Total number of times of original:\", len(all_labels)/ORIG_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data size: 3777\n",
      "Loading augmentated training data...20% done!\n",
      "Loading augmentated training data...40% done!\n",
      "Loading augmentated training data...60% done!\n",
      "Loading augmentated training data...80% done!\n",
      "Loading augmentated training data...100% done!\n",
      "original train data size: 3019\n",
      "augmented train data size: 120760\n",
      "number of times augmented: 40\n",
      "validation data size: 758\n"
     ]
    }
   ],
   "source": [
    "train_labels, val_labels = train_val_labels_split(all_labels, train_size = 0.8)\n",
    "aug_labels = aug_train_labels(train_labels)\n",
    "train_labels = shuffle(train_labels, random_state = RANDOM_STATE)\n",
    "val_labels = shuffle(val_labels, random_state = RANDOM_STATE)\n",
    "aug_labels = shuffle(val_labels, random_state = RANDOM_STATE)\n",
    "print \"original train data size:\", len(train_labels)\n",
    "print \"augmented train data size:\", len(aug_labels)\n",
    "print \"number of times augmented:\", len(aug_labels)/len(train_labels)\n",
    "print \"validation data size:\", len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top = False, input_shape=(224,224,3))\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(8, activation='softmax')(x)\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  11/4025 [..............................] - ETA: 2005s - loss: 2.3142\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-44565b449c6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                               \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                               \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINPUT_WIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINPUT_HEIGHT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                               validation_steps = 30)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/a/data/fisheries_monitoring/data/models/classifiers/classifier2.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/a/h/jli04/Envs/deep-venv/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/a/h/jli04/Envs/deep-venv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1874\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1875\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1876\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/a/h/jli04/Envs/deep-venv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1618\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/a/h/jli04/Envs/deep-venv/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/a/h/jli04/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/a/h/jli04/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/a/h/jli04/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/a/h/jli04/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/a/h/jli04/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 30\n",
    "steps_per_epoch = len(aug_labels) / batch_size\n",
    "nb_epoch = 30\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=0),]\n",
    "\n",
    "history = model.fit_generator(generator = data_generator(batch_size, aug_labels, INPUT_WIDTH, INPUT_HEIGHT), \n",
    "                              steps_per_epoch = steps_per_epoch,\n",
    "                              epochs=nb_epoch,\n",
    "                              verbose=1,\n",
    "                              callbacks = callbacks,\n",
    "                              validation_data = data_generator(batch_size, val_labels, INPUT_WIDTH, INPUT_HEIGHT),\n",
    "                              validation_steps = 30)\n",
    "model.save('/a/data/fisheries_monitoring/data/models/classifiers/classifier3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_test, y_test, id_test, X_test_raw = load_data(val_labels, INPUT_WIDTH, INPUT_HEIGHT)\n",
    "predictions_valid = model.predict(X_test.astype('float32'), batch_size=batch_size, verbose=1)\n",
    "score = log_loss(y_test, predictions_valid)\n",
    "print \"log loss score: \", score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = np.argmax(predictions_valid, axis = 1)\n",
    "acc = accuracy_score(y_test, y_pred, normalize=True, sample_weight=None)\n",
    "print \"accuracy: \", acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print y_test[0:35]\n",
    "print y_pred[0:35]\n",
    "\n",
    "print y_test[35:70]\n",
    "print y_pred[35:70]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
