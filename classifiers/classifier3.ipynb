{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras import __version__ as keras_version\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 8574\n",
    "INPUT_WIDTH = 224\n",
    "INPUT_HEIGHT = 224\n",
    "DATA_PATH = '/a/data/fisheries_monitoring/data/classifiers/superbox/'\n",
    "ORIG_PATH = DATA_PATH + 'original'\n",
    "ORIG_DIST = {}\n",
    "CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "for cls in  CLASSES:\n",
    "    files = glob.glob(ORIG_PATH + '/' + cls + '/*.jpg')\n",
    "    ORIG_DIST[cls] = len(files)\n",
    "print \"Number of examples in each class of the original data:\"\n",
    "for key, val in ORIG_DIST.iteritems():\n",
    "    print key, '\\t', val\n",
    "ORIG_SIZE = sum(ORIG_DIST.values())\n",
    "print \"Total number of examples in original data:\", ORIG_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_all_labels(folders):\n",
    "    all_img = []\n",
    "    all_file_class = []\n",
    "    for folder in folders:\n",
    "        img = []\n",
    "        file_class = []\n",
    "        folder_name = os.path.basename(folder)\n",
    "        print('Loading augmentation: {}'.format(folder_name))\n",
    "        classes = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "        for idx, cls in enumerate(classes):\n",
    "            path = os.path.join(DATA_PATH, folder, cls, '*.jpg')\n",
    "            files = sorted(glob.glob(path))\n",
    "            for fl in files:\n",
    "                flbase = os.path.basename(fl)\n",
    "                img.append(folder_name + '/' + cls + '/' + flbase)\n",
    "                file_class.append(idx) \n",
    "        print \"Number of examples:\", len(file_class)\n",
    "        print \"Times of original:\", len(file_class)/ORIG_SIZE\n",
    "        print\n",
    "        all_img += img\n",
    "        all_file_class += file_class\n",
    "    all_labels = pd.DataFrame({\"img\":all_img, \"classes\":all_file_class})\n",
    "    all_labels = all_labels[[\"img\", \"classes\"]]\n",
    "    return all_labels\n",
    "\n",
    "\n",
    "\n",
    "def train_val_labels_split(labels, train_size = 0.8):\n",
    "    org_labels = labels[labels[\"img\"].str.startswith(\"original\")]\n",
    "    print \"original data size:\", len(org_labels)\n",
    "    train = []\n",
    "    test = []\n",
    "    for i in xrange(8):\n",
    "        train_tmp, test_tmp = train_test_split(org_labels[org_labels[\"classes\"] == i], train_size = train_size, random_state = RANDOM_STATE)\n",
    "        train.append(train_tmp)\n",
    "        test.append(test_tmp)\n",
    "    return pd.concat(train), pd.concat(test)\n",
    "\n",
    "def aug_train_labels(labels):\n",
    "    aug = []\n",
    "    i = 0\n",
    "    for label in labels[\"img\"]:\n",
    "        label = label[9:-4]\n",
    "        aug.append(all_labels[all_labels[\"img\"].str.contains(label)])\n",
    "        if (i+1) in [k*len(labels)/5 for k in xrange(1,6)]:\n",
    "            print \"Loading augmentated training data...{}% done!\".format((i+2)*100/len(labels))\n",
    "        i += 1\n",
    "    return pd.concat(aug)\n",
    "\n",
    "def data_generator(batch_size, labels, INPUT_WIDTH, INPUT_HEIGHT):\n",
    "    while True:\n",
    "        img_batch = np.zeros((batch_size, INPUT_WIDTH, INPUT_HEIGHT, 3))\n",
    "        class_batch = np.zeros((batch_size, 8))\n",
    "        for i in xrange(batch_size):\n",
    "            n = np.random.choice(len(labels))\n",
    "            file_name = labels.iloc[n][\"img\"]\n",
    "            path = DATA_PATH + file_name\n",
    "            img = image.load_img(path)\n",
    "            img = img.resize((INPUT_WIDTH, INPUT_HEIGHT))\n",
    "            img = image.img_to_array(img)\n",
    "            img /= 255\n",
    "            img_batch[i] = img\n",
    "            \n",
    "            class_batch[i] = np_utils.to_categorical(labels.iloc[n][\"classes\"], 8)\n",
    "        \n",
    "        yield (img_batch, class_batch)\n",
    "\n",
    "\n",
    "def load_data(labels, INPUT_WIDTH, INPUT_HEIGHT):\n",
    "    X = []\n",
    "    y = []\n",
    "    idx = []\n",
    "    X_raw = []\n",
    "    y_raw = [] \n",
    "    shape_raw = []\n",
    "    for i in xrange(len(labels)):\n",
    "        file_name = labels.iloc[i][\"img\"]\n",
    "        path = DATA_PATH + file_name\n",
    "        img_raw = image.load_img(path)\n",
    "        img = img_raw.resize((INPUT_WIDTH,INPUT_HEIGHT))\n",
    "        \n",
    "        img_raw = image.img_to_array(img_raw)\n",
    "        img_raw /= 255\n",
    "        img = image.img_to_array(img)\n",
    "        img /= 255\n",
    "        \n",
    "        file_class = labels.iloc[i][\"classes\"]\n",
    "\n",
    "        X.append(img)\n",
    "        y.append(file_class)\n",
    "        idx.append(file_name)\n",
    "        X_raw.append(img_raw)\n",
    "        \n",
    "        if (i+1) in [k*len(labels)/5 for k in xrange(1,6)]:\n",
    "                print \"Loading...{}% done!\".format((i+2)*100/len(labels))\n",
    "        \n",
    "    return np.array(X), np.array(y), np.array(idx), np.array(X_raw)\n",
    "\n",
    "\n",
    "def visualize_prediction(img, index = None, true_box = None, pred_box = None, ax = None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, 1, figsize=(12,8))\n",
    "    ax.imshow(img)\n",
    "    if index is not None:\n",
    "        ax.set_title(index)\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    \n",
    "    if true_box is not None:\n",
    "        x, y, w, h = true_box\n",
    "        x = x * width\n",
    "        y = y * height\n",
    "        w = w * width\n",
    "        h = h * height\n",
    "        ax.add_patch(\n",
    "        patches.Rectangle(\n",
    "            (x, y), # x,y\n",
    "            w, # width\n",
    "            h, # height\n",
    "            hatch='\\\\',\n",
    "            fill=False,      # remove background\n",
    "            color = 'r',\n",
    "            linewidth = 2.5\n",
    "                )\n",
    "            )\n",
    "    if pred_box is not None:\n",
    "        x, y, w, h = pred_box\n",
    "        x = x * width\n",
    "        y = y * height\n",
    "        w = w * width\n",
    "        h = h * height\n",
    "        ax.add_patch(\n",
    "        patches.Rectangle(\n",
    "            (x, y), # x,y\n",
    "            w, # width\n",
    "            h, # height\n",
    "            hatch='-',\n",
    "            fill=False,      # remove background\n",
    "            color = 'k',\n",
    "            linewidth = 2.5\n",
    "                )\n",
    "            )\n",
    "\n",
    "def make_plot(data, nrow = 2, ncol = 2, index = None, true_box = None, pred_box = None, figsize = (15,8)):\n",
    "    # Create grid\n",
    "    _, ax = plt.subplots(nrow, ncol, figsize=figsize)\n",
    "    \n",
    "    idx = None\n",
    "    tbox = None\n",
    "    pbox = None\n",
    "    # Generate indices of images to show\n",
    "    for axi in np.ravel(ax):\n",
    "        n = np.random.choice(len(data))\n",
    "        img = data[n]\n",
    "        if index is not None:\n",
    "            idx = index[n]\n",
    "        if true_box is not None:\n",
    "            tbox = true_box[n]\n",
    "        if pred_box is not None:\n",
    "            pbox = pred_box[n]\n",
    "        \n",
    "        # Visualize it along with the box\n",
    "        visualize_prediction(img, index = idx, true_box = tbox, pred_box = pbox, ax = axi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_folders = glob.glob(DATA_PATH + '*')\n",
    "all_labels = load_all_labels(all_folders)\n",
    "print \"Total number of examples:\", len(all_labels)\n",
    "print \"Total number of times of original:\", len(all_labels)/ORIG_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_labels, val_labels = train_val_labels_split(all_labels, train_size = 0.8)\n",
    "aug_labels = aug_train_labels(train_labels)\n",
    "train_labels = shuffle(train_labels, random_state = RANDOM_STATE)\n",
    "val_labels = shuffle(val_labels, random_state = RANDOM_STATE)\n",
    "aug_labels = shuffle(val_labels, random_state = RANDOM_STATE)\n",
    "print \"original train data size:\", len(train_labels)\n",
    "print \"augmented train data size:\", len(aug_labels)\n",
    "print \"number of times augmented:\", len(aug_labels)/len(train_labels)\n",
    "print \"validation data size:\", len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top = False, input_shape=(224,224,3))\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(8, activation='softmax')(x)\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "steps_per_epoch = len(aug_labels) / batch_size\n",
    "nb_epoch = 30\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=0),]\n",
    "\n",
    "history = model.fit_generator(generator = data_generator(batch_size, aug_labels, INPUT_WIDTH, INPUT_HEIGHT), \n",
    "                              steps_per_epoch = steps_per_epoch,\n",
    "                              epochs=nb_epoch,\n",
    "                              verbose=1,\n",
    "                              callbacks = callbacks,\n",
    "                              validation_data = data_generator(batch_size, val_labels, INPUT_WIDTH, INPUT_HEIGHT),\n",
    "                              validation_steps = 30)\n",
    "model.save('/a/data/fisheries_monitoring/data/models/classifiers/classifier3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = load_model('/a/data/fisheries_monitoring/data/models/classifiers/classifier3.h5')\n",
    "X_test, y_test, id_test, X_test_raw = load_data(val_labels, INPUT_WIDTH, INPUT_HEIGHT)\n",
    "predictions_valid = model.predict(X_test.astype('float32'), batch_size=30, verbose=1)\n",
    "score = log_loss(y_test, predictions_valid)\n",
    "print \"log loss score: \", score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = np.argmax(predictions_valid, axis = 1)\n",
    "acc = accuracy_score(y_test, y_pred, normalize=True, sample_weight=None)\n",
    "print \"accuracy: \", acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print y_test[0:35]\n",
    "print y_pred[0:35]\n",
    "\n",
    "print y_test[35:70]\n",
    "print y_pred[35:70]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
