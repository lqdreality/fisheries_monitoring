{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras import __version__ as keras_version\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '/a/data/fisheries_monitoring/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_cropped_train():\n",
    "    X_train = []\n",
    "    X_train_id = []\n",
    "    y_train = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('Read train images')\n",
    "    folders = ['ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT', 'NoF']\n",
    "    for fld in folders:\n",
    "        index = folders.index(fld)\n",
    "        print('Load folder {} (Index: {})'.format(fld, index))\n",
    "        path = os.path.join(DATA_PATH + 'classifiers/superbox/', fld, '*.jpg')\n",
    "        files = sorted(glob.glob(path))\n",
    "        for fl in files:\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = image.load_img(fl, target_size=(224, 224))\n",
    "            img = image.img_to_array(img)\n",
    "            X_train.append(img)\n",
    "            X_train_id.append(fld + '/' + flbase)\n",
    "            y_train.append(index)\n",
    "\n",
    "    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return X_train, y_train, X_train_id\n",
    "\n",
    "def read_and_normalize_cropped_train_data():\n",
    "    train_data, train_target, train_id = load_cropped_train()\n",
    "\n",
    "    print('Convert to numpy...')\n",
    "    train_data = np.array(train_data)\n",
    "    train_target = np.array(train_target)\n",
    "\n",
    "    print('Convert to float...')\n",
    "    train_data = train_data.astype('float32')\n",
    "    train_data = train_data / 255\n",
    "    train_target = np_utils.to_categorical(train_target, 8)\n",
    "\n",
    "    print('Train shape:', train_data.shape)\n",
    "    print(train_data.shape[0], 'train samples')\n",
    "    return train_data, train_target, train_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train images\n",
      "Load folder ALB (Index: 0)\n",
      "Load folder BET (Index: 1)\n",
      "Load folder DOL (Index: 2)\n",
      "Load folder LAG (Index: 3)\n",
      "Load folder OTHER (Index: 4)\n",
      "Load folder SHARK (Index: 5)\n",
      "Load folder YFT (Index: 6)\n",
      "Load folder NoF (Index: 7)\n",
      "Read train data time: 44.1 seconds\n",
      "Convert to numpy...\n",
      "Convert to float...\n",
      "('Train shape:', (3777, 224, 224, 3))\n",
      "(3777, 'train samples')\n"
     ]
    }
   ],
   "source": [
    "train_data, train_target, train_id = read_and_normalize_cropped_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top = False, input_shape=(224,224,3))\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(8, activation='softmax')(x)\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "nb_epoch = 30\n",
    "random_state = 51\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3868 samples, validate on 968 samples\n",
      "Epoch 1/30\n",
      "58s - loss: 1.0148 - val_loss: 4.9977\n",
      "Epoch 2/30\n",
      "57s - loss: 0.6599 - val_loss: 6.6429\n",
      "Epoch 3/30\n",
      "57s - loss: 0.5281 - val_loss: 7.7167\n",
      "Epoch 4/30\n",
      "57s - loss: 0.4406 - val_loss: 2.2186\n",
      "Epoch 5/30\n",
      "57s - loss: 0.3767 - val_loss: 0.4230\n",
      "Epoch 6/30\n",
      "57s - loss: 0.3404 - val_loss: 0.3760\n",
      "Epoch 7/30\n",
      "57s - loss: 0.3106 - val_loss: 0.3305\n",
      "Epoch 8/30\n",
      "57s - loss: 0.2789 - val_loss: 0.3237\n",
      "Epoch 9/30\n",
      "57s - loss: 0.2397 - val_loss: 0.3593\n",
      "Epoch 10/30\n",
      "57s - loss: 0.2271 - val_loss: 0.2952\n",
      "Epoch 11/30\n",
      "57s - loss: 0.2087 - val_loss: 0.3165\n",
      "Epoch 12/30\n",
      "57s - loss: 0.1861 - val_loss: 0.2840\n",
      "Epoch 13/30\n",
      "57s - loss: 0.1713 - val_loss: 0.2883\n",
      "Epoch 14/30\n",
      "57s - loss: 0.1573 - val_loss: 0.2651\n",
      "Epoch 15/30\n",
      "57s - loss: 0.1474 - val_loss: 0.2616\n",
      "Epoch 16/30\n",
      "57s - loss: 0.1276 - val_loss: 0.2506\n",
      "Epoch 17/30\n",
      "57s - loss: 0.1333 - val_loss: 0.2523\n",
      "Epoch 18/30\n",
      "57s - loss: 0.1203 - val_loss: 0.2498\n",
      "Epoch 19/30\n",
      "57s - loss: 0.1101 - val_loss: 0.2527\n",
      "Epoch 20/30\n",
      "57s - loss: 0.1070 - val_loss: 0.2467\n",
      "Epoch 21/30\n",
      "57s - loss: 0.0968 - val_loss: 0.2419\n",
      "Epoch 22/30\n",
      "57s - loss: 0.0823 - val_loss: 0.2521\n",
      "Epoch 23/30\n",
      "57s - loss: 0.0753 - val_loss: 0.2630\n"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=0),]\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, shuffle=True,\n",
    "          verbose=2, validation_data=(X_test, y_test), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions_valid = model.predict(X_test.astype('float32'), batch_size=batch_size, verbose=2)\n",
    "score = log_loss(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"log loss score: \", score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_true = np.argmax(y_test, axis = 1)\n",
    "y_pred = np.argmax(predictions_valid, axis = 1)\n",
    "acc = accuracy_score(y_true, y_pred, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"accuracy: \", acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print y_true[0:35]\n",
    "print y_pred[0:35]\n",
    "\n",
    "print y_true[35:70]\n",
    "print y_pred[35:70]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
