{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras import __version__ as keras_version\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_cropped_train():\n",
    "    X_train = []\n",
    "    X_train_id = []\n",
    "    y_train = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('Read train images')\n",
    "    folders = ['ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT']\n",
    "    for fld in folders:\n",
    "        index = folders.index(fld)\n",
    "        print('Load folder {} (Index: {})'.format(fld, index))\n",
    "        path = os.path.join('cropped_data', fld, '*.jpg')\n",
    "        files = sorted(glob.glob(path))\n",
    "        for fl in files:\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = image.load_img(fl, target_size=(299, 299))\n",
    "            img = image.img_to_array(img)\n",
    "            X_train.append(img)\n",
    "            X_train_id.append(fld + '/' + flbase)\n",
    "            y_train.append(index)\n",
    "\n",
    "    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return X_train, y_train, X_train_id\n",
    "\n",
    "def read_and_normalize_cropped_train_data():\n",
    "    train_data, train_target, train_id = load_cropped_train()\n",
    "\n",
    "    print('Convert to numpy...')\n",
    "    train_data = np.array(train_data)\n",
    "    train_target = np.array(train_target)\n",
    "\n",
    "    print('Convert to float...')\n",
    "    train_data = train_data.astype('float32')\n",
    "    train_data = train_data / 255\n",
    "    train_target = np_utils.to_categorical(train_target, 8)\n",
    "\n",
    "    print('Train shape:', train_data.shape)\n",
    "    print(train_data.shape[0], 'train samples')\n",
    "    return train_data, train_target, train_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train images\n",
      "Load folder ALB (Index: 0)\n",
      "Load folder BET (Index: 1)\n",
      "Load folder DOL (Index: 2)\n",
      "Load folder LAG (Index: 3)\n",
      "Load folder OTHER (Index: 4)\n",
      "Load folder SHARK (Index: 5)\n",
      "Load folder YFT (Index: 6)\n",
      "Read train data time: 27.69 seconds\n",
      "Convert to numpy...\n",
      "Convert to float...\n",
      "('Train shape:', (4371, 299, 299, 3))\n",
      "(4371, 'train samples')\n"
     ]
    }
   ],
   "source": [
    "train_data, train_target, train_id = read_and_normalize_cropped_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(8, activation='softmax')(x)\n",
    "# this is the model we will train\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "nb_epoch = 30\n",
    "random_state = 51\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3496 samples, validate on 875 samples\n",
      "Epoch 1/30\n",
      "75s - loss: 0.6114 - val_loss: 0.6613\n",
      "Epoch 2/30\n",
      "75s - loss: 0.5875 - val_loss: 0.6538\n",
      "Epoch 3/30\n",
      "75s - loss: 0.5648 - val_loss: 0.6752\n",
      "Epoch 4/30\n",
      "75s - loss: 0.5422 - val_loss: 0.6934\n",
      "Epoch 5/30\n",
      "75s - loss: 0.5424 - val_loss: 0.7287\n",
      "Epoch 6/30\n",
      "75s - loss: 0.5299 - val_loss: 0.5913\n",
      "Epoch 7/30\n",
      "75s - loss: 0.5018 - val_loss: 0.6690\n",
      "Epoch 8/30\n",
      "75s - loss: 0.4825 - val_loss: 0.6614\n",
      "Epoch 9/30\n",
      "75s - loss: 0.4722 - val_loss: 0.5614\n",
      "Epoch 10/30\n",
      "75s - loss: 0.4808 - val_loss: 0.5637\n",
      "Epoch 11/30\n",
      "75s - loss: 0.4686 - val_loss: 0.7041\n",
      "Epoch 12/30\n",
      "75s - loss: 0.4533 - val_loss: 0.6013\n",
      "Epoch 13/30\n",
      "75s - loss: 0.4507 - val_loss: 0.5387\n",
      "Epoch 14/30\n",
      "75s - loss: 0.4348 - val_loss: 0.5472\n",
      "Epoch 15/30\n",
      "75s - loss: 0.4074 - val_loss: 0.5306\n",
      "Epoch 16/30\n",
      "75s - loss: 0.3952 - val_loss: 0.5555\n",
      "Epoch 17/30\n",
      "75s - loss: 0.4007 - val_loss: 0.6027\n",
      "Epoch 18/30\n",
      "75s - loss: 0.3822 - val_loss: 0.5369\n",
      "Epoch 19/30\n",
      "75s - loss: 0.3821 - val_loss: 0.5544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xfa2bf50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=0),]\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, shuffle=True,\n",
    "          verbose=2, validation_data=(X_test, y_test), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions_valid = model.predict(X_train.astype('float32'), batch_size=batch_size, verbose=2)\n",
    "score = log_loss(y_train, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss score:  0.285989247257\n"
     ]
    }
   ],
   "source": [
    "print \"log loss score: \", score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_true = np.argmax(y_test, axis = 1)\n",
    "y_pred = np.argmax(predictions_valid, axis = 1)\n",
    "acc = accuracy_score(y_true, y_pred, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy:  0.813714285714\n"
     ]
    }
   ],
   "source": [
    "print \"accuracy: \", acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 5 0 6 0 0 0 0 6 0 0 6 6 0 0 0 0 6 0 6 0 6 0 6 0 0 5 6 0 0 0 0 0 1 0 0 1\n",
      " 0 1 4 0 0 0 0 6 0 2 0 0 0 1 0 0 0 3 6 6 6 6 4 6 0 1 0 0 0 6 0 0 6 6 0 0 0\n",
      " 0 1 6 0 0 0 0 6 0 0 0 4 0 3 0 0 0 0 6 0 6 0 6 0 0 0]\n",
      "[0 5 0 2 0 0 0 6 0 0 0 6 6 0 0 0 0 6 0 6 0 6 0 6 0 0 5 6 0 6 0 0 0 1 4 0 0\n",
      " 0 6 4 0 0 0 0 6 0 2 0 0 0 1 4 0 0 3 1 6 6 6 4 6 0 1 0 0 1 0 0 0 0 4 0 1 0\n",
      " 0 0 6 0 1 0 0 6 6 0 0 4 0 3 4 6 0 0 6 0 6 0 6 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print y_true[0:100]\n",
    "print y_pred[0:100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
